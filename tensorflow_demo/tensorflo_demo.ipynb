{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd026261d6663085c58a05028b261ddcaf6e8498ee173f6cf308ab2fece185123cf",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tensorflow\n",
    "\n",
    "En esta práctica se realizará un ejercicio usando la librería de inteligencia artificial `tensorflow`, en un documento interactivo Jupyter Notebook usando Python 3.8.8."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A continuación se construirá una red neuronal artificial la cual será entrenada para identificar caracteres escritos a mano. Primero importaremos la librería:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "source": [
    "Y cargamos el conjunto de datos MNIST, el cual contiene las imágenes de caracteres escritos a mano y será lo que usaremos tanto para entrenar como para probar la red neuronal:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "source": [
    "Con la API de Keras podemos usar todas las características de Tensorflow de manera sencilla, pues para construir la red neuronal basta con agregar capa por capa de manera secuencial, esto lo logramos con unas cuantas líneas de código:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # capa de entrada\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # capa de procesamiento\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # capa para prevenir sobreentrenamiento\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # capa de salida\n",
    "    tf.keras.layers.Dense(10),\n",
    "    # capa para calcular probabilidades\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "source": [
    "Ahora pasaremos a entrenar el modelo con una parte del conjunto de datos:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 3ms/step - loss: 0.4822 - accuracy: 0.8579\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1488 - accuracy: 0.9563\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9678\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0840 - accuracy: 0.9727\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0616 - accuracy: 0.9801\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0550 - accuracy: 0.9816\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0483 - accuracy: 0.9846\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0429 - accuracy: 0.9853\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0413 - accuracy: 0.9871\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16329743760>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    # función de pérdida, calcula el logaritmo negativo de una predicción verdadera\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# 10 iteraciones\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "source": [
    "Después de diez iteraciones, el modelo reportó una precisión de 98.7% sobre el conjunto de datos de entrenamiento. Ya que entrenamos a la red neuronal, pasaremos a utilizar un método para evaluar qué tanto podemos confiar en las predicciones de nuestro modelo:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 - 1s - loss: 0.0742 - accuracy: 0.9793\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.07423324882984161, 0.9793000221252441]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "source": [
    "Esta evaluación nos indica que la precisión real, es decir, después de haber probado el modelo con nuevos datos que nunca había visto, es de 97.9%, lo cual es normal que sea menor que la precisión de entrenamiento pues queremos ver la eficiencia de la red neuronal al predecir datos totalmente nuevos."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}